{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statisical biases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "custom_palette = sns.color_palette('viridis', 2)\n",
    "sns.set_palette(custom_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpson's paradox\n",
    "\n",
    "## Berkeley Admissions Case Study\n",
    "\n",
    "\n",
    "In the 70's, a study was conducted to evaluate whether there was gender-based discrimination in admissions to the university. \n",
    "\n",
    "The data is from six departments, called A-F.\n",
    "\n",
    "We have information on whether the applicant was male or female and whether they were admitted or rejected.\n",
    "\n",
    "We will examine whether there is discrimination against women in admission. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "admissions_df = pd.read_csv('ucb-admit.csv')  \n",
    "display(admissions_df)\n",
    "admissions_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring gender bias\n",
    "What can we say about the overall admission distribution based on gender?\n",
    "\n",
    "Let's create a plot comparing the admission rates for males and females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# admissions rates for males/females\n",
    "admissions_df['Admitted_Boolean'] = admissions_df['Admit'].apply(lambda x: 1 if x=='Admitted' else 0)\n",
    "ax = sns.catplot(data=admissions_df, x='Gender', y='Admitted_Boolean', kind='bar')\n",
    "ax.set(ylabel=\"proportion admitted\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error bar is an approximate 95% bootstrapped confidence interval!\n",
    "\n",
    "What do you think? Is there bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing conclusions: Exercise\n",
    "Is the difference in admission rates by gender statistically significant, at the 5% significance level?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete code for hypothesis testing\n",
    "''' HINT: you can re-use code from the previous lectures - you'll need to compute difference between averages,\n",
    "run simulations, compute the confidence interval, and draw a conclusion'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is your conclusion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore: Which departments admit females in lower rates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.catplot(x='Dept', y='Admitted_Boolean', hue='Gender', data=admissions_df, hue_order=['Male','Female'], kind=\"bar\")\n",
    "ax.set(ylabel=\"proportion admitted\", xlabel=\"department\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happened?\n",
    "How come we do not see evidence for bias against females in admission rates in any department, and yet overall we see a difference in admission rates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpby_dept_gender = admissions_df.groupby(['Dept','Gender'])\n",
    "counts_by_dept_gender = grpby_dept_gender.count().reset_index()\n",
    "counts_by_dept_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax=sns.catplot(data=counts_by_dept_gender, x='Dept', y='Admit', hue='Gender', kind='bar',hue_order=['Male','Female'])\n",
    "ax.set(ylabel=\"Number of applicants\", xlabel=\"department\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The inspection paradox\n",
    "\n",
    "## Example: Purdue class size\n",
    "Purdue is a large public university in Indiana. \n",
    "\n",
    "Students in Purdue have been complaining about the class sizes, raising the issue that they are too big and it is hard to have meaningful discussions. \n",
    "\n",
    "The board of education asked the dean to provide data regarding the distribution of undergraduate class sizes. Here is the outuput of the dean's report:\n",
    "\n",
    "<img src=\"purdue fig.png\">\n",
    "\n",
    "(note that this is a bad way to show this type of information as it violates visualization principles that we discussed.) \n",
    "\n",
    "Yet, the Student Body in Purdue claims to have surveyd many students and the results were very different\n",
    "\n",
    "We will now check how this is possible. First, we will create all classes in campus, as listed by the dean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class size data originally from\n",
    "# https://www.purdue.edu/datadigest/2013-14/InstrStuLIfe/DistUGClasses.html\n",
    "# now available from\n",
    "# https://web.archive.org/web/20160415011613/https://www.purdue.edu/datadigest/2013-14/InstrStuLIfe/DistUGClasses.html\n",
    "\n",
    "sizes_bins = [(1, 1), \n",
    "              (2, 9),\n",
    "              (10, 19),\n",
    "              (20, 29),\n",
    "              (30, 39),\n",
    "              (40, 49),\n",
    "              (50, 99),\n",
    "              (100, 300)] # we assume 300 is the largest class possible\n",
    "\n",
    "size_counts = [138, 635, 1788, 1979, 796, 354, 487, 333]\n",
    "\n",
    "# This function creates actual (unbinned) classes\n",
    "def get_all_classes(sizes_bins, size_counts):\n",
    "    classes = []\n",
    "    for i in np.arange(len(sizes_bins)):\n",
    "        (low, high) = sizes_bins[i]\n",
    "        count = size_counts[i]\n",
    "        sample_class = np.random.randint(low, high+1, count)\n",
    "        classes.extend(sample_class)\n",
    "    return np.array(classes)\n",
    "\n",
    "dean_class_report = get_all_classes(sizes_bins, size_counts)\n",
    "dean_class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0,301,10)\n",
    "ax=sns.displot(dean_class_report, bins=bins, stat='probability')\n",
    "ax.set(xlabel=\"class size\", title=\"Dean's report\")\n",
    "print('Average class size, according to dean:', dean_class_report.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get the Student Body's estimates. \n",
    "\n",
    "Let's say that the survey asked \"in your most recent class, how many students were there?\" We will further assume that each answer given reflects the true number of students in the class (no errors).\n",
    "\n",
    "The crucial point is that the chances of sampling a student getting out from a class with 10 students is 10 divided by total number of students, whereas the chances of sampling a student getting out from a class with 100 students is 10 times as much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000 # number of students sampled to answer the survey\n",
    "def sample_students_from_classes(all_class_sizes):\n",
    "    probs = all_class_sizes/np.sum(all_class_sizes) #probability to sample a student walking out from each of the \"actual\" classes\n",
    "    sample_students = np.random.choice(all_class_sizes, size=N, replace=True, p=probs) # with replacement because we may sample more than one student from the same class\n",
    "    return(sample_students)\n",
    "\n",
    "students_class_report = sample_students_from_classes(dean_class_report)\n",
    "students_class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.displot(students_class_report, bins=bins, stat='probability')\n",
    "ax.set(xlabel='class size', title='Student Body survey')\n",
    "print('Average class size, according to students:', students_class_report.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the two distributions on the same graph\n",
    "\n",
    "# If we want to use Seaborn, we need them both in the same data frame\n",
    "dean_df = pd.DataFrame(dean_class_report, columns=['class size'])\n",
    "students_df = pd.DataFrame(students_class_report, columns=['class size'])\n",
    "dean_students_combined = pd.concat([dean_df.assign(according_to='dean'), students_df.assign(according_to='students')], ignore_index=True)\n",
    "display(dean_students_combined)\n",
    "\n",
    "# then, we can use the hue argument, along with common_norm=False, to compare the distributions on the same probability scale\n",
    "sns.displot(data=dean_students_combined, x='class size', hue='according_to', stat='probability', bins=bins, common_norm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the students are much more likely to report studying in large (>40 students) classes, and much less likely to report studying in small classes.\n",
    "\n",
    "This is an example of the inspection paradox."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Times between trains\n",
    "\n",
    "The inspection paradox also happens when waiting for public transportation. Buses and trains are supposed to arrive at constant intervals, but in practice some intervals are longer than others. When arriving at a random time to the station, you are more likely to arrive within a long interval, simply because it is longer\n",
    "\n",
    "Here is some data from trains in Boston. We will compare what passengers and what the train company \"see\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Times between consecutive trains (in sec)\n",
    "time_between_trains = [\n",
    "    428.0, 705.0, 407.0, 465.0, 433.0, 425.0, 204.0, 506.0, 143.0, 351.0, \n",
    "    450.0, 598.0, 464.0, 749.0, 341.0, 586.0, 754.0, 256.0, 378.0, 435.0, \n",
    "    176.0, 405.0, 360.0, 519.0, 648.0, 374.0, 483.0, 537.0, 578.0, 534.0, \n",
    "    577.0, 619.0, 538.0, 331.0, 186.0, 629.0, 193.0, 360.0, 660.0, 484.0, \n",
    "    512.0, 315.0, 457.0, 404.0, 740.0, 388.0, 357.0, 485.0, 567.0, 160.0, \n",
    "    428.0, 387.0, 901.0, 187.0, 622.0, 616.0, 585.0, 474.0, 442.0, 499.0, \n",
    "    437.0, 620.0, 351.0, 286.0, 373.0, 232.0, 393.0, 745.0, 636.0, 758.0,\n",
    "]\n",
    "np.array(time_between_trains).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000 # number of people arriving to train station\n",
    "def sample_times_between_trains():\n",
    "    probs = time_between_trains/np.sum(time_between_trains) \n",
    "    sample_times = np.random.choice(time_between_trains, size=N, replace=True, p=probs)\n",
    "    return(sample_times)\n",
    "\n",
    "experienced_time_between_trains = sample_times_between_trains()\n",
    "experienced_time_between_trains.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(90, 811, 30)\n",
    "\n",
    "company_df = pd.DataFrame(time_between_trains, columns=['wait time'])\n",
    "passenger_df = pd.DataFrame(experienced_time_between_trains, columns=['wait time'])\n",
    "company_passenger_combined = pd.concat([company_df.assign(according_to='train company'), passenger_df.assign(according_to='passengers')], ignore_index=True)\n",
    "display(company_passenger_combined)\n",
    "\n",
    "# then, we can use the hue argument, along with common_norm=False, to compare the distributions on the same probability scale\n",
    "sns.displot(data=company_passenger_combined, x='wait time', hue='according_to', stat='probability', bins=bins, common_norm=False)\n",
    "\n",
    "# plt.hist(time_between_trains, bins=bins, alpha=0.6, label='train company', density=True)\n",
    "# plt.hist(experienced_time_between_trains, bins=bins, alpha=0.4, label='passengers',density=True)\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.xlabel('time in seconds')\n",
    "# plt.ylabel('density')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we see that passengers' wait times are longer than the real time between trains"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
